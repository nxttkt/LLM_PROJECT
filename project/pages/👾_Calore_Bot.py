from dotenv import load_dotenv
load_dotenv()

import os
import streamlit as st
import sys
import requests
import re

# ‚úÖ ‡πÉ‡∏ä‡πâ OpenAI SDK v1
from openai import OpenAI

API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = os.getenv("MODEL")
USDA_API_KEY = os.getenv("USDA_API_KEY")

st.set_page_config(
    page_title="CALORE BOT",
    page_icon="ü§ñ",
)

BOT_PROMPT = (
    "You are CALORE Bot. Respond in Thai with a detailed, structured nutrition report. "
    "If USDA/retrieval data is available, use it. If not, provide a clearly-labeled ESTIMATE "
    "based on common recipes WITHOUT asking follow-ups or apologizing. Include:\n"
    "1) ‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠ 100 ‡∏Å‡∏£‡∏±‡∏° ‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≠ 1 ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü (‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì)\n"
    "2) ‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô ‡πÑ‡∏Ç‡∏°‡∏±‡∏ô ‡∏Ñ‡∏≤‡∏£‡πå‡∏ö (‡πÅ‡∏•‡∏∞‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≤‡∏î‡πÑ‡∏î‡πâ ‡πÉ‡∏™‡πà ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡πÉ‡∏¢‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡πÇ‡∏ã‡πÄ‡∏î‡∏µ‡∏¢‡∏°)\n"
    "3) ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡∏™‡∏π‡∏ï‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≤‡∏ß ~180‚Äì200 g, ‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô ~1 ‡∏ä‡πâ‡∏≠‡∏ô‡πÇ‡∏ï‡πä‡∏∞)\n"
    "4) ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡πà‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Ñ‡∏•‡∏≠‡∏£‡∏µ‡πà/‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û\n"
    "Keep it factual and organized with bullet points."
)

# ----------------------------- RAG ---------------------------------
def get_food_data(food_item):
    if not USDA_API_KEY:
        return None

    queries = food_item if isinstance(food_item, list) else [food_item]
    for q in queries:
        url = f"https://api.nal.usda.gov/fdc/v1/foods/search?query={q}&api_key={USDA_API_KEY}"
        try:
            r = requests.get(url, timeout=15)
            r.raise_for_status()
            data = r.json()
            if not data.get("foods"):
                continue

            first = data["foods"][0]
            desc = (first.get("description") or "").lower()

            # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏ï‡∏±‡∏ß‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠
            tokens = [t for t in q.lower().split() if t.isalpha()]
            if tokens and not any(tok in desc for tok in tokens):
                continue

            return first
        except Exception:
            continue
    return None  # fallback ‡πÑ‡∏õ OpenAI


def rag_chatbot(query, food_name=None):
    # ‡πÉ‡∏ä‡πâ OpenAI SDK v1
    client = OpenAI(api_key=API_KEY)

    food_info = get_food_data(food_name or query)
    if not food_info:
        return None   # ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÑ‡∏õ‡πÉ‡∏ä‡πâ OpenAI ‡∏ï‡πà‡∏≠

    name = food_info.get("description", "N/A")
    nutrients = food_info.get("foodNutrients", [])

    def pick(nnum):
        for n in nutrients:
            if str(n.get("nutrientNumber")) == nnum:
                return n.get("value")
        return None

    cal  = pick("208"); protein = pick("203"); fat = pick("204"); carb = pick("205")

    # ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô/‡∏¢‡∏≤‡∏ß‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏±‡πâ‡∏á ‡πÅ‡∏ï‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î
    context = (
        f"Name: {name}\n"
        f"Calories: {cal} kcal per 100g\n"
        f"Protein: {protein} g\n"
        f"Fat: {fat} g\n"
        f"Carbohydrate: {carb} g\n"
    )

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å query
    is_english = bool(re.search(r"[A-Za-z]", query))
    lang = "English" if is_english else "Thai"

    messages = [
        {
            "role": "system",
            "content": (
                "You are a nutrition assistant. Use only the given CONTEXT. "
                "Answer briefly with numeric facts in the requested language "
                "(per 100 g, per serving if present)."
            ),
        },
        {
            "role": "user",
            "content": f"CONTEXT:\n{context}\n\nQUESTION: {query}\nAnswer in {lang}.",
        },
    ]

    resp = client.chat.completions.create(
        model=MODEL or "gpt-3.5-turbo",
        messages=messages,
        temperature=0,
        top_p=1,
        presence_penalty=0,
        frequency_penalty=0,
    )
    return resp.choices[0].message.content.strip()
# --------------------------- /RAG ----------------------------------


# ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô)
THAI_FOOD_MAP = {
    "‡∏Ç‡πâ‡∏≤‡∏ß‡∏ú‡∏±‡∏î": "fried rice",
    "‡∏ú‡∏±‡∏î‡πÑ‡∏ó‡∏¢": "pad thai",
}

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å (‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
FOOD_WORDS = [
    "fried rice", "rice", "chicken", "pork", "egg", "noodle", "soup", "curry",
    "green curry", "pad thai", "hainanese chicken rice", "spaghetti",
]

def detect_food_from_text(text: str) -> str | None:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡∏Å‡∏±‡∏ô None/‡∏ä‡∏ô‡∏¥‡∏î‡∏≠‡∏∑‡πà‡∏ô‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏ß‡∏¢)"""
    if not text or not isinstance(text, str):
        return None

    t = text.lower().strip()

    # ‡∏•‡∏≠‡∏á‡∏à‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢‡∏î‡∏π‡∏Å‡πà‡∏≠‡∏ô
    for th, en in THAI_FOOD_MAP.items():
        if th in t:
            return en  # ‡∏Ñ‡∏∑‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡πâ‡∏ô‡πÉ‡∏ô USDA

    # ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
    for w in FOOD_WORDS:
        if w in t:
            return w

    # ‡∏•‡∏≠‡∏á regex ‡∏î‡∏π (‡∏≠‡∏≤‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏¢‡∏≤‡∏ß‡πÜ ‡πÑ‡∏î‡πâ)
    m = re.search(r"(fried rice|green curry|tom yum|pad thai|hainanese chicken rice)", t)
    if m:
        return m.group(1)

    # ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
    return None

FOLLOWUP_HINTS = [
    "‡πÅ‡∏•‡πâ‡∏ß", "‡∏ï‡πà‡∏≠", "‡∏≠‡∏µ‡∏Å", "‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà", "‡∏Å‡∏µ‡πà‡πÅ‡∏Ñ‡∏•", "‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô", "‡πÑ‡∏Ç‡∏°‡∏±‡∏ô", "‡∏Ñ‡∏≤‡∏£‡πå‡∏ö",
    "sugar", "fiber", "sodium"
]

def is_followup(text: str) -> bool:
    t = (text or "").strip().lower()
    return (detect_food_from_text(t) is None) and any(w in t for w in FOLLOWUP_HINTS)


def init_session_state():
    """Initialize session state variables"""
    if "last_food" not in st.session_state:
        st.session_state.last_food = ""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "llm_client" not in st.session_state:
        # Create a safe llm_client: try OpenAI if available and configured,
        # otherwise provide a lightweight fallback that avoids AttributeError.
        def create_llm_client():
            try:
                if not API_KEY:
                    raise RuntimeError("OPENAI_API_KEY not set")

                model_name = MODEL or "gpt-3.5-turbo"

                class OpenAIClient:
                    def __init__(self, api_key, model):
                        # ‚úÖ ‡πÉ‡∏ä‡πâ SDK v1
                        self.client = OpenAI(api_key=api_key)
                        self.model = model

                    def chat(self, messages):
                        final_messages = [{"role": "system", "content": BOT_PROMPT}]
                        final_messages.extend(messages)

                        resp = self.client.chat.completions.create(
                            model=self.model,
                            messages=final_messages,
                            temperature=0,
                            top_p=1,
                            presence_penalty=0,
                            frequency_penalty=0,
                        )
                        return resp.choices[0].message.content.strip()

                return OpenAIClient(API_KEY, model_name)
            except Exception:
                # Fallback: a minimal client that echoes the last user message
                class EchoClient:
                    def chat(self, messages):
                        if not messages:
                            return "(no messages)"
                        last = messages[-1].get("content", "")
                        return "(LLM unavailable) I would respond to: '" + last + "'"

                return EchoClient()

        st.session_state.llm_client = create_llm_client()

def display_chat_messages():
    """Display chat messages"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])


init_session_state()

st.title("CALORE Bot")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# React to user input
if prompt := st.chat_input("Type your message here..."):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session
    food_in_msg = detect_food_from_text(prompt)
    if food_in_msg:
        st.session_state.last_food = food_in_msg

    # Display user message
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate and display assistant response
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            # ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ
            query_food = detect_food_from_text(prompt)
            if query_food:
                st.session_state.last_food = query_food
            elif is_followup(prompt) and st.session_state.last_food:
                query_food = st.session_state.last_food
            else:
                query_food = None

            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å RAG ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô
            response = None
            if query_food:
                response = rag_chatbot(prompt, query_food)

            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏≠‡∏≤‡∏´‡∏≤‡∏£ (‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà follow-up ‡∏ó‡∏µ‡πà‡∏û‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ) ‚Üí ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°
            if response is None and query_food is None:
                response = (
                    "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ "
                    "‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡∏∞ "
                    "‡πÄ‡∏ä‡πà‡∏ô ‚Äú‡∏ú‡∏±‡∏î‡πÑ‡∏ó‡∏¢ 1 ‡∏à‡∏≤‡∏ô‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚Äú‡∏≠‡∏Å‡πÑ‡∏Å‡πà‡∏¢‡πà‡∏≤‡∏á 150 ‡∏Å‡∏£‡∏±‡∏°‚Äù?"
                )

            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏ï‡πà RAG ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‚Üí ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏° BOT_PROMPT
            if response is None and query_food is not None:
                response = st.session_state.llm_client.chat(
                    [{"role": "user", "content": prompt}]
                )

            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            st.markdown(response)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó
    st.session_state.messages.append({"role": "assistant", "content": response})
